{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erfOlc-T8kY3"
      },
      "source": [
        "# **BentoML Example: Linear Regression with Paddlepaddle**\n",
        "**BentoML makes moving trained ML models to production easy:**\n",
        "\n",
        "\n",
        "\n",
        "*   Package models trained with any ML framework and reproduce them for model serving in production\n",
        "* **Deploy anywhere** for online API serving or offline batch serving\n",
        "* High-Performance API model server with adaptive micro-batching support\n",
        "* Central hub for managing models and deployment process via Web UI and APIs\n",
        "* Modular and flexible design making it adaptable to your infrastrcuture\n",
        "\n",
        "BentoML is a framework for serving, managing, and deploying machine learning models. It is aiming to bridge the gap between Data Science and DevOps, and enable teams to deliver prediction services in a fast, repeatable, and scalable way.\n",
        "\n",
        "Before reading this example project, be sure to check out the [Getting started guide](https://github.com/bentoml/BentoML/blob/master/guides/quick-start/bentoml-quick-start-guide.ipynb) to learn about the basic concepts in BentoML.\n",
        "\n",
        "This notebook demonstrates how to use BentoML to turn a paddlepaddle model into a docker image containing a REST API server serving this model, how to use your ML service built with BentoML as a CLI tool, and how to distribute it a pypi package.\n",
        "\n",
        "The example is based on [this tutorial](https://www.paddlepaddle.org.cn/documentation/docs/en/1.5/beginners_guide/basics/fit_a_line/README.html), using dataset from the [UCI Machine Learning Repository](https://www.kaggle.com/schirmerchad/bostonhoustingmlnd)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54jFhiru8NWO"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHOPuMGm-Nl2",
        "outputId": "5e08ea9b-b356-4908-a3a2-b949b733f4e0"
      },
      "source": [
        "!python -m pip install git+https://github.com/bentoml/BentoML.git\n",
        "\n",
        "#!pip install -q bentoml 'paddlepaddle>=2.0.0' 'pandas>=1.1.1' 'numpy>=1.8.2'\n",
        "!pip install paddlepaddle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/bentoml/BentoML.git\n",
            "  Cloning https://github.com/bentoml/BentoML.git to /tmp/pip-req-build-jhg8dqoj\n",
            "  Running command git clone -q https://github.com/bentoml/BentoML.git /tmp/pip-req-build-jhg8dqoj\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (5.4.8)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (5.0.2)\n",
            "Requirement already satisfied: deepmerge in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (0.2.1)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (4.4.4)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (0.9.0)\n",
            "Requirement already satisfied: sqlalchemy<1.4.0,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (1.3.24)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (3.0.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (0.8.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (2.8.1)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (2.0.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (1.1.2)\n",
            "Requirement already satisfied: sqlalchemy-utils<0.36.8 in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (0.36.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (2020.12.5)\n",
            "Requirement already satisfied: cerberus in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (1.3.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (3.12.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (1.17.43)\n",
            "Requirement already satisfied: dependency-injector<5.0,>=4.0 in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (4.31.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (7.1.2)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (1.5.8)\n",
            "Requirement already satisfied: urllib3<=1.25.11 in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (1.24.3)\n",
            "Requirement already satisfied: schema in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (0.7.4)\n",
            "Requirement already satisfied: gunicorn in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (20.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (3.7.4.post0)\n",
            "Requirement already satisfied: humanfriendly in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (20.9)\n",
            "Requirement already satisfied: ruamel.yaml>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (0.17.2)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.7/dist-packages (from BentoML==0.12.0+14.g0fac537) (1.32.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from docker->BentoML==0.12.0+14.g0fac537) (1.15.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from docker->BentoML==0.12.0+14.g0fac537) (0.58.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->BentoML==0.12.0+14.g0fac537) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->BentoML==0.12.0+14.g0fac537) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->BentoML==0.12.0+14.g0fac537) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from cerberus->BentoML==0.12.0+14.g0fac537) (54.2.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->BentoML==0.12.0+14.g0fac537) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3->BentoML==0.12.0+14.g0fac537) (0.3.6)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.43 in /usr/local/lib/python3.7/dist-packages (from boto3->BentoML==0.12.0+14.g0fac537) (1.20.43)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/dist-packages (from alembic->BentoML==0.12.0+14.g0fac537) (1.0.4)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->BentoML==0.12.0+14.g0fac537) (1.1.4)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from schema->BentoML==0.12.0+14.g0fac537) (0.5.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->BentoML==0.12.0+14.g0fac537) (1.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->BentoML==0.12.0+14.g0fac537) (20.3.0)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->BentoML==0.12.0+14.g0fac537) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->BentoML==0.12.0+14.g0fac537) (3.7.4.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->BentoML==0.12.0+14.g0fac537) (5.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->BentoML==0.12.0+14.g0fac537) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->BentoML==0.12.0+14.g0fac537) (2.4.7)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.15.0->BentoML==0.12.0+14.g0fac537) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->BentoML==0.12.0+14.g0fac537) (1.1.1)\n",
            "Building wheels for collected packages: BentoML\n",
            "  Building wheel for BentoML (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for BentoML: filename=BentoML-0.12.0+14.g0fac537-cp37-none-any.whl size=1132685 sha256=a77ef8785b050713eef53fafdee64380df6b93fdbfa379e60eb4ccd1d2100a93\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dzy5155a/wheels/07/f4/e4/75cd038b063ebca70861fabd2631c5475542e880d5bafcad65\n",
            "Successfully built BentoML\n",
            "Installing collected packages: BentoML\n",
            "  Found existing installation: BentoML 0.12.0\n",
            "    Uninstalling BentoML-0.12.0:\n",
            "      Successfully uninstalled BentoML-0.12.0\n",
            "Successfully installed BentoML-0.12.0+14.g0fac537\n",
            "Requirement already satisfied: paddlepaddle in /usr/local/lib/python3.7/dist-packages (2.0.1)\n",
            "Requirement already satisfied: numpy>=1.13; python_version >= \"3.5\" and platform_system != \"Windows\" in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (1.19.5)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (0.8.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (7.1.2)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (3.12.4)\n",
            "Requirement already satisfied: gast>=0.3.3; platform_system != \"Windows\" in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (0.3.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (4.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from paddlepaddle) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle) (2020.12.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.1.0->paddlepaddle) (54.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTmhsmvk-iZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0476512f-ff91-4866-edbc-cfaf53aab51e"
      },
      "source": [
        "import numpy as np\n",
        "import paddle\n",
        "import paddle.nn as nn\n",
        "import paddle.optimizer as opt\n",
        "import pandas as pd\n",
        "\n",
        "import bentoml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-01 21:26:54,239 - INFO - No local BentoML config file found, using default configurations\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CeOjFaR_e2x"
      },
      "source": [
        "# **Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yayroXhE-sos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3583d945-5047-47e2-8756-6b4c5b3f5af0"
      },
      "source": [
        "import paddle\n",
        "import numpy as np\n",
        "import bentoml\n",
        "from paddle.static import InputSpec\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "BATCH_NUM = 4\n",
        "EPOCH_NUM = 5\n",
        "\n",
        "IN_FEATURES = 13\n",
        "OUT_FEATURES = 1\n",
        "\n",
        "class LinearNet(paddle.nn.Layer):\n",
        "    def __init__(self):\n",
        "        super(LinearNet, self).__init__()\n",
        "        self._linear = paddle.nn.Linear(IN_FEATURES, OUT_FEATURES)\n",
        "\n",
        "    @paddle.jit.to_static(input_spec=[InputSpec(shape=[IN_FEATURES], dtype='float32')])\n",
        "    def forward(self, x):\n",
        "        return self._linear(x)\n",
        "\n",
        "    def train(self, loader, loss_fn, opt):\n",
        "        for epoch_id in range(EPOCH_NUM):\n",
        "            for batch_id, (image, label) in enumerate(loader()):\n",
        "                out = self._linear(image)\n",
        "                loss = loss_fn(out, label)\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "                opt.clear_grad()\n",
        "                print(\"Epoch {} batch {}: loss = {}\".format(\n",
        "                    epoch_id, batch_id, np.mean(loss.numpy())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  return (isinstance(seq, collections.Sequence) and\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEiqsFpJ_qk-"
      },
      "source": [
        "# **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhiqk3VP_mqe",
        "outputId": "04ca085e-629f-4f6d-f82c-4f06ef1f580f"
      },
      "source": [
        "model = LinearNet()\n",
        "loss_fn = paddle.nn.MSELoss()\n",
        "adam = paddle.optimizer.Adam(parameters=model.parameters())\n",
        "\n",
        "dataset = paddle.text.datasets.UCIHousing(mode=\"train\")\n",
        "\n",
        "loader = paddle.io.DataLoader(dataset,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  shuffle=True,\n",
        "  drop_last=True,\n",
        "  num_workers=2)\n",
        "\n",
        "model.train(loader, loss_fn, adam)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 batch 0: loss = 623.5848388671875\n",
            "Epoch 0 batch 1: loss = 905.6049194335938\n",
            "Epoch 0 batch 2: loss = 792.160888671875\n",
            "Epoch 0 batch 3: loss = 780.5050048828125\n",
            "Epoch 0 batch 4: loss = 627.6819458007812\n",
            "Epoch 0 batch 5: loss = 525.576904296875\n",
            "Epoch 0 batch 6: loss = 434.99334716796875\n",
            "Epoch 0 batch 7: loss = 430.06915283203125\n",
            "Epoch 0 batch 8: loss = 500.126953125\n",
            "Epoch 0 batch 9: loss = 764.2137451171875\n",
            "Epoch 0 batch 10: loss = 478.6463623046875\n",
            "Epoch 0 batch 11: loss = 678.7437744140625\n",
            "Epoch 0 batch 12: loss = 1200.9666748046875\n",
            "Epoch 0 batch 13: loss = 405.596923828125\n",
            "Epoch 0 batch 14: loss = 544.1121826171875\n",
            "Epoch 0 batch 15: loss = 702.2733154296875\n",
            "Epoch 0 batch 16: loss = 924.8780517578125\n",
            "Epoch 0 batch 17: loss = 889.0203857421875\n",
            "Epoch 0 batch 18: loss = 417.31298828125\n",
            "Epoch 0 batch 19: loss = 797.6754150390625\n",
            "Epoch 0 batch 20: loss = 599.2960815429688\n",
            "Epoch 0 batch 21: loss = 397.35791015625\n",
            "Epoch 0 batch 22: loss = 657.08642578125\n",
            "Epoch 0 batch 23: loss = 505.5260314941406\n",
            "Epoch 0 batch 24: loss = 489.11993408203125\n",
            "Epoch 0 batch 25: loss = 947.4429931640625\n",
            "Epoch 0 batch 26: loss = 665.806396484375\n",
            "Epoch 0 batch 27: loss = 581.926513671875\n",
            "Epoch 0 batch 28: loss = 947.0526123046875\n",
            "Epoch 0 batch 29: loss = 695.8004150390625\n",
            "Epoch 0 batch 30: loss = 701.1072387695312\n",
            "Epoch 0 batch 31: loss = 652.4229736328125\n",
            "Epoch 0 batch 32: loss = 690.674072265625\n",
            "Epoch 0 batch 33: loss = 772.3773193359375\n",
            "Epoch 0 batch 34: loss = 950.7506103515625\n",
            "Epoch 0 batch 35: loss = 402.71270751953125\n",
            "Epoch 0 batch 36: loss = 631.4700317382812\n",
            "Epoch 0 batch 37: loss = 313.10125732421875\n",
            "Epoch 0 batch 38: loss = 769.114990234375\n",
            "Epoch 0 batch 39: loss = 676.21142578125\n",
            "Epoch 0 batch 40: loss = 477.90496826171875\n",
            "Epoch 0 batch 41: loss = 506.629638671875\n",
            "Epoch 0 batch 42: loss = 707.7115478515625\n",
            "Epoch 0 batch 43: loss = 530.5272827148438\n",
            "Epoch 0 batch 44: loss = 958.6387939453125\n",
            "Epoch 0 batch 45: loss = 999.27783203125\n",
            "Epoch 0 batch 46: loss = 954.2285766601562\n",
            "Epoch 0 batch 47: loss = 523.9896240234375\n",
            "Epoch 0 batch 48: loss = 578.7178955078125\n",
            "Epoch 0 batch 49: loss = 516.3453369140625\n",
            "Epoch 1 batch 0: loss = 753.554443359375\n",
            "Epoch 1 batch 1: loss = 458.43499755859375\n",
            "Epoch 1 batch 2: loss = 936.2098388671875\n",
            "Epoch 1 batch 3: loss = 365.7144775390625\n",
            "Epoch 1 batch 4: loss = 652.6239013671875\n",
            "Epoch 1 batch 5: loss = 984.2484741210938\n",
            "Epoch 1 batch 6: loss = 813.465087890625\n",
            "Epoch 1 batch 7: loss = 557.2491455078125\n",
            "Epoch 1 batch 8: loss = 639.8633422851562\n",
            "Epoch 1 batch 9: loss = 358.829345703125\n",
            "Epoch 1 batch 10: loss = 480.4271240234375\n",
            "Epoch 1 batch 11: loss = 695.821533203125\n",
            "Epoch 1 batch 12: loss = 681.3548583984375\n",
            "Epoch 1 batch 13: loss = 497.76031494140625\n",
            "Epoch 1 batch 14: loss = 618.684814453125\n",
            "Epoch 1 batch 15: loss = 606.7737426757812\n",
            "Epoch 1 batch 16: loss = 693.1472778320312\n",
            "Epoch 1 batch 17: loss = 670.8422241210938\n",
            "Epoch 1 batch 18: loss = 407.9947204589844\n",
            "Epoch 1 batch 19: loss = 1077.0029296875\n",
            "Epoch 1 batch 20: loss = 806.5994873046875\n",
            "Epoch 1 batch 21: loss = 550.1364135742188\n",
            "Epoch 1 batch 22: loss = 455.70050048828125\n",
            "Epoch 1 batch 23: loss = 578.040283203125\n",
            "Epoch 1 batch 24: loss = 569.705322265625\n",
            "Epoch 1 batch 25: loss = 990.8988037109375\n",
            "Epoch 1 batch 26: loss = 994.5960693359375\n",
            "Epoch 1 batch 27: loss = 663.446533203125\n",
            "Epoch 1 batch 28: loss = 692.2489624023438\n",
            "Epoch 1 batch 29: loss = 853.376708984375\n",
            "Epoch 1 batch 30: loss = 476.94610595703125\n",
            "Epoch 1 batch 31: loss = 653.0362548828125\n",
            "Epoch 1 batch 32: loss = 620.4510498046875\n",
            "Epoch 1 batch 33: loss = 656.374267578125\n",
            "Epoch 1 batch 34: loss = 436.5618896484375\n",
            "Epoch 1 batch 35: loss = 558.8120727539062\n",
            "Epoch 1 batch 36: loss = 553.919921875\n",
            "Epoch 1 batch 37: loss = 575.8868408203125\n",
            "Epoch 1 batch 38: loss = 836.9566650390625\n",
            "Epoch 1 batch 39: loss = 548.938232421875\n",
            "Epoch 1 batch 40: loss = 509.67108154296875\n",
            "Epoch 1 batch 41: loss = 1392.0859375\n",
            "Epoch 1 batch 42: loss = 574.26611328125\n",
            "Epoch 1 batch 43: loss = 914.2640380859375\n",
            "Epoch 1 batch 44: loss = 359.2345275878906\n",
            "Epoch 1 batch 45: loss = 916.4850463867188\n",
            "Epoch 1 batch 46: loss = 568.409423828125\n",
            "Epoch 1 batch 47: loss = 660.4852294921875\n",
            "Epoch 1 batch 48: loss = 746.309814453125\n",
            "Epoch 1 batch 49: loss = 513.88720703125\n",
            "Epoch 2 batch 0: loss = 619.9252319335938\n",
            "Epoch 2 batch 1: loss = 485.80987548828125\n",
            "Epoch 2 batch 2: loss = 777.9547119140625\n",
            "Epoch 2 batch 3: loss = 716.5533447265625\n",
            "Epoch 2 batch 4: loss = 513.2099609375\n",
            "Epoch 2 batch 5: loss = 904.5167846679688\n",
            "Epoch 2 batch 6: loss = 593.7144775390625\n",
            "Epoch 2 batch 7: loss = 482.28070068359375\n",
            "Epoch 2 batch 8: loss = 550.8648071289062\n",
            "Epoch 2 batch 9: loss = 593.5643310546875\n",
            "Epoch 2 batch 10: loss = 920.11962890625\n",
            "Epoch 2 batch 11: loss = 468.6513671875\n",
            "Epoch 2 batch 12: loss = 606.8564453125\n",
            "Epoch 2 batch 13: loss = 516.8242797851562\n",
            "Epoch 2 batch 14: loss = 584.3304443359375\n",
            "Epoch 2 batch 15: loss = 713.56005859375\n",
            "Epoch 2 batch 16: loss = 1017.364990234375\n",
            "Epoch 2 batch 17: loss = 515.2655639648438\n",
            "Epoch 2 batch 18: loss = 954.0641479492188\n",
            "Epoch 2 batch 19: loss = 933.0535888671875\n",
            "Epoch 2 batch 20: loss = 372.3396301269531\n",
            "Epoch 2 batch 21: loss = 755.292724609375\n",
            "Epoch 2 batch 22: loss = 818.6812744140625\n",
            "Epoch 2 batch 23: loss = 977.7489013671875\n",
            "Epoch 2 batch 24: loss = 829.529052734375\n",
            "Epoch 2 batch 25: loss = 607.2041015625\n",
            "Epoch 2 batch 26: loss = 323.736328125\n",
            "Epoch 2 batch 27: loss = 881.921142578125\n",
            "Epoch 2 batch 28: loss = 445.5794372558594\n",
            "Epoch 2 batch 29: loss = 705.8031005859375\n",
            "Epoch 2 batch 30: loss = 587.4639892578125\n",
            "Epoch 2 batch 31: loss = 596.4715576171875\n",
            "Epoch 2 batch 32: loss = 738.0458374023438\n",
            "Epoch 2 batch 33: loss = 807.8812255859375\n",
            "Epoch 2 batch 34: loss = 839.9031982421875\n",
            "Epoch 2 batch 35: loss = 477.8743896484375\n",
            "Epoch 2 batch 36: loss = 376.44854736328125\n",
            "Epoch 2 batch 37: loss = 682.0736083984375\n",
            "Epoch 2 batch 38: loss = 480.3860778808594\n",
            "Epoch 2 batch 39: loss = 522.170654296875\n",
            "Epoch 2 batch 40: loss = 906.9429931640625\n",
            "Epoch 2 batch 41: loss = 558.4222412109375\n",
            "Epoch 2 batch 42: loss = 705.99853515625\n",
            "Epoch 2 batch 43: loss = 577.8585205078125\n",
            "Epoch 2 batch 44: loss = 651.150146484375\n",
            "Epoch 2 batch 45: loss = 821.0037231445312\n",
            "Epoch 2 batch 46: loss = 723.5064697265625\n",
            "Epoch 2 batch 47: loss = 492.2858581542969\n",
            "Epoch 2 batch 48: loss = 581.5869140625\n",
            "Epoch 2 batch 49: loss = 661.9578857421875\n",
            "Epoch 3 batch 0: loss = 503.88909912109375\n",
            "Epoch 3 batch 1: loss = 532.7095947265625\n",
            "Epoch 3 batch 2: loss = 522.2650756835938\n",
            "Epoch 3 batch 3: loss = 794.42431640625\n",
            "Epoch 3 batch 4: loss = 954.2279052734375\n",
            "Epoch 3 batch 5: loss = 453.59368896484375\n",
            "Epoch 3 batch 6: loss = 1020.1758422851562\n",
            "Epoch 3 batch 7: loss = 442.0072021484375\n",
            "Epoch 3 batch 8: loss = 691.777099609375\n",
            "Epoch 3 batch 9: loss = 725.1412353515625\n",
            "Epoch 3 batch 10: loss = 581.3922729492188\n",
            "Epoch 3 batch 11: loss = 653.8060913085938\n",
            "Epoch 3 batch 12: loss = 413.7892761230469\n",
            "Epoch 3 batch 13: loss = 842.7008056640625\n",
            "Epoch 3 batch 14: loss = 657.9656982421875\n",
            "Epoch 3 batch 15: loss = 738.4058837890625\n",
            "Epoch 3 batch 16: loss = 568.5172119140625\n",
            "Epoch 3 batch 17: loss = 838.8192138671875\n",
            "Epoch 3 batch 18: loss = 592.64013671875\n",
            "Epoch 3 batch 19: loss = 722.92041015625\n",
            "Epoch 3 batch 20: loss = 521.82958984375\n",
            "Epoch 3 batch 21: loss = 679.7924194335938\n",
            "Epoch 3 batch 22: loss = 453.56805419921875\n",
            "Epoch 3 batch 23: loss = 333.771240234375\n",
            "Epoch 3 batch 24: loss = 632.0752563476562\n",
            "Epoch 3 batch 25: loss = 938.4583740234375\n",
            "Epoch 3 batch 26: loss = 739.6534423828125\n",
            "Epoch 3 batch 27: loss = 485.992919921875\n",
            "Epoch 3 batch 28: loss = 639.8182373046875\n",
            "Epoch 3 batch 29: loss = 436.0423278808594\n",
            "Epoch 3 batch 30: loss = 354.05474853515625\n",
            "Epoch 3 batch 31: loss = 413.7607116699219\n",
            "Epoch 3 batch 32: loss = 738.6390380859375\n",
            "Epoch 3 batch 33: loss = 1032.79150390625\n",
            "Epoch 3 batch 34: loss = 794.8515625\n",
            "Epoch 3 batch 35: loss = 814.2843017578125\n",
            "Epoch 3 batch 36: loss = 608.0460205078125\n",
            "Epoch 3 batch 37: loss = 693.00634765625\n",
            "Epoch 3 batch 38: loss = 778.2470092773438\n",
            "Epoch 3 batch 39: loss = 544.0328369140625\n",
            "Epoch 3 batch 40: loss = 1009.1485595703125\n",
            "Epoch 3 batch 41: loss = 633.1827392578125\n",
            "Epoch 3 batch 42: loss = 629.5065307617188\n",
            "Epoch 3 batch 43: loss = 389.85174560546875\n",
            "Epoch 3 batch 44: loss = 714.595947265625\n",
            "Epoch 3 batch 45: loss = 300.1128845214844\n",
            "Epoch 3 batch 46: loss = 559.3060302734375\n",
            "Epoch 3 batch 47: loss = 745.2586669921875\n",
            "Epoch 3 batch 48: loss = 824.5000610351562\n",
            "Epoch 3 batch 49: loss = 662.7113037109375\n",
            "Epoch 4 batch 0: loss = 637.1376953125\n",
            "Epoch 4 batch 1: loss = 404.61676025390625\n",
            "Epoch 4 batch 2: loss = 601.3607177734375\n",
            "Epoch 4 batch 3: loss = 866.3539428710938\n",
            "Epoch 4 batch 4: loss = 656.5691528320312\n",
            "Epoch 4 batch 5: loss = 763.4610595703125\n",
            "Epoch 4 batch 6: loss = 552.3900146484375\n",
            "Epoch 4 batch 7: loss = 818.5574951171875\n",
            "Epoch 4 batch 8: loss = 712.22900390625\n",
            "Epoch 4 batch 9: loss = 651.4306030273438\n",
            "Epoch 4 batch 10: loss = 402.3460693359375\n",
            "Epoch 4 batch 11: loss = 975.6088256835938\n",
            "Epoch 4 batch 12: loss = 429.3876953125\n",
            "Epoch 4 batch 13: loss = 703.4373779296875\n",
            "Epoch 4 batch 14: loss = 747.9479370117188\n",
            "Epoch 4 batch 15: loss = 341.2940673828125\n",
            "Epoch 4 batch 16: loss = 424.38458251953125\n",
            "Epoch 4 batch 17: loss = 778.1935424804688\n",
            "Epoch 4 batch 18: loss = 467.45892333984375\n",
            "Epoch 4 batch 19: loss = 493.79656982421875\n",
            "Epoch 4 batch 20: loss = 664.2079467773438\n",
            "Epoch 4 batch 21: loss = 403.82928466796875\n",
            "Epoch 4 batch 22: loss = 735.1343994140625\n",
            "Epoch 4 batch 23: loss = 1112.502685546875\n",
            "Epoch 4 batch 24: loss = 566.3684692382812\n",
            "Epoch 4 batch 25: loss = 904.1103515625\n",
            "Epoch 4 batch 26: loss = 748.218994140625\n",
            "Epoch 4 batch 27: loss = 1146.00830078125\n",
            "Epoch 4 batch 28: loss = 578.2838745117188\n",
            "Epoch 4 batch 29: loss = 833.936279296875\n",
            "Epoch 4 batch 30: loss = 729.4205322265625\n",
            "Epoch 4 batch 31: loss = 1130.946533203125\n",
            "Epoch 4 batch 32: loss = 559.25732421875\n",
            "Epoch 4 batch 33: loss = 560.7507934570312\n",
            "Epoch 4 batch 34: loss = 1128.427734375\n",
            "Epoch 4 batch 35: loss = 657.0340576171875\n",
            "Epoch 4 batch 36: loss = 376.1456298828125\n",
            "Epoch 4 batch 37: loss = 548.6507568359375\n",
            "Epoch 4 batch 38: loss = 420.595947265625\n",
            "Epoch 4 batch 39: loss = 772.7349243164062\n",
            "Epoch 4 batch 40: loss = 512.911376953125\n",
            "Epoch 4 batch 41: loss = 677.3181762695312\n",
            "Epoch 4 batch 42: loss = 561.3084716796875\n",
            "Epoch 4 batch 43: loss = 513.4924926757812\n",
            "Epoch 4 batch 44: loss = 631.8885498046875\n",
            "Epoch 4 batch 45: loss = 558.9163818359375\n",
            "Epoch 4 batch 46: loss = 601.9522705078125\n",
            "Epoch 4 batch 47: loss = 328.0657958984375\n",
            "Epoch 4 batch 48: loss = 643.1988525390625\n",
            "Epoch 4 batch 49: loss = 686.8999633789062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CstExs3Savqn"
      },
      "source": [
        " test_x = np.array([[-0.0405441 ,  0.06636364, -0.32356227, -0.06916996, -0.03435197,\n",
        "        0.05563625, -0.03475696,  0.02682186, -0.37171335, -0.21419304,\n",
        "       -0.33569506,  0.10143217, -0.21172912]]).astype('float32')\n",
        "\n",
        "df_test_x = pd.DataFrame(test_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7qADc_KcJI-"
      },
      "source": [
        "import csv\n",
        "\n",
        "with open('test.csv', 'w', newline='') as csvfile:\n",
        "    spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
        "    spamwriter.writerow(df_test_x.columns)\n",
        "    spamwriter.writerow([-0.0405441 ,  0.06636364, -0.32356227, -0.06916996, -0.03435197,\n",
        "        0.05563625, -0.03475696,  0.02682186, -0.37171335, -0.21419304,\n",
        "       -0.33569506,  0.10143217, -0.21172912])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcrHdbJxAHh0"
      },
      "source": [
        "# **Create BentoService for model serving**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_T8YQRjALqg",
        "outputId": "6cad4945-01d4-4d55-dacc-298a971c33ed"
      },
      "source": [
        "%%writefile paddle_linear_regression.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import bentoml\n",
        "from bentoml import env, artifacts, api, BentoService\n",
        "from bentoml.adapters import DataframeInput\n",
        "from bentoml.frameworks.paddle import PaddlePaddleModelArtifact\n",
        "\n",
        "@env(infer_pip_packages=True)\n",
        "@artifacts([PaddlePaddleModelArtifact('model')])\n",
        "class PaddleLinearRegression(bentoml.BentoService):\n",
        "\n",
        "  @api(input=DataframeInput(), batch=True)\n",
        "  def predict(self, df: pd.DataFrame):\n",
        "        input_data = df.to_numpy().astype('float32')\n",
        "\n",
        "        predictor = self.artifacts.model\n",
        "        input_names = predictor.get_input_names()\n",
        "        input_handle = predictor.get_input_handle(input_names[0])\n",
        "\n",
        "        input_handle.reshape(input_data.shape)\n",
        "        input_handle.copy_from_cpu(input_data)\n",
        "\n",
        "        predictor.run()\n",
        "\n",
        "        output_names = predictor.get_output_names()\n",
        "        output_handle = predictor.get_output_handle(output_names[0])\n",
        "        output_data = output_handle.copy_to_cpu()\n",
        "\n",
        "        return output_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting paddle_linear_regression.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "ESc4D_muCWNx",
        "outputId": "97885274-8055-4b42-c443-de1e47880078"
      },
      "source": [
        "# 1) import the custom BentoService defined above\n",
        "from paddle_linear_regression import PaddleLinearRegression\n",
        "\n",
        "# 2) `pack` it with required artifacts\n",
        "bento_svc = PaddleLinearRegression()\n",
        "bento_svc.pack('model', model)\n",
        "\n",
        "# 3) save your BentoSerivce\n",
        "saved_path = bento_svc.save()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-04-01 21:28:46,182] WARNING - pip package requirement pandas already exist\n",
            "[2021-04-01 21:28:46,184] WARNING - pip package requirement paddlepaddle already exist\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-01 21:28:46,195 - INFO - Context impl SQLiteImpl.\n",
            "2021-04-01 21:28:46,196 - INFO - Will assume non-transactional DDL.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2021-04-01 21:28:46,931] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.12.0, but loading from BentoML version 0.12.0+14.g0fac537\n",
            "[2021-04-01 21:28:47,014] INFO - BentoService bundle 'PaddleLinearRegression:20210401212846_F88F15' saved to: /root/bentoml/repository/PaddleLinearRegression/20210401212846_F88F15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-8e9ab721ae9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msaved_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbento_svc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mbento_svc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/paddle_linear_regression.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifacts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0minput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0minput_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bentoml/service/artifacts/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mBentoServiceArtifact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mSklearn\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \"\"\"\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mBentoServiceArtifact\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bentoml/service/artifacts/__init__.py\u001b[0m in \u001b[0;36mwrapped_get\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m                     )\n\u001b[1;32m    194\u001b[0m                 \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_get\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bentoml/frameworks/paddle.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m             )\n\u001b[1;32m    102\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_memory_optim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle_infer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: (NotFound) Cannot open file /tmp/bentoml-temp-8baaijv3/PaddleLinearRegression/artifacts/model.pdmodel, please confirm whether the file is normal.\n  [Hint: Expected static_cast<bool>(fin.is_open()) == true, but received static_cast<bool>(fin.is_open()):0 != true:1.] (at /paddle/paddle/fluid/inference/api/analysis_predictor.cc:915)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvUU0k0JCxYk"
      },
      "source": [
        "# **REST API Model Serving**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeJEIDyj_xGK",
        "outputId": "0d3d5d3e-d82c-4f8e-d307-78773e49e7bc"
      },
      "source": [
        "!bentoml serve PaddleLinearRegression:latest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n",
            "[2021-04-01 21:29:16,663] INFO - Getting latest version PaddleLinearRegression:20210401212846_F88F15\n",
            "[2021-04-01 21:29:16,683] INFO - Starting BentoML API proxy in development mode..\n",
            "[2021-04-01 21:29:16,685] INFO - Starting BentoML API server in development mode..\n",
            "[2021-04-01 21:29:16,890] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
            "[2021-04-01 21:29:16,911] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.12.0, but loading from BentoML version 0.12.0+14.g0fac537\n",
            "[2021-04-01 21:29:16,914] INFO - Your system nofile limit is 1048576, which means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors for the server process, or launch more microbatch instances to accept more concurrent connection.\n",
            "======== Running on http://0.0.0.0:5000 ========\n",
            "(Press CTRL+C to quit)\n",
            "[2021-04-01 21:29:17,386] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
            "[2021-04-01 21:29:17,405] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.12.0, but loading from BentoML version 0.12.0+14.g0fac537\n",
            "/usr/local/lib/python3.7/dist-packages/paddle/fluid/backward.py:1640: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  return list(x) if isinstance(x, collections.Sequence) else [x]\n",
            " * Serving Flask app \"PaddleLinearRegression\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n",
            "2021-04-01 21:29:19,971 - INFO -  * Running on http://127.0.0.1:50135/ (Press CTRL+C to quit)\n",
            "\n",
            "\n",
            "--------------------------------------\n",
            "C++ Traceback (most recent call last):\n",
            "--------------------------------------\n",
            "0   bvar::detail::SamplerCollector::sampling_thread(void*)\n",
            "1   bvar::detail::SamplerCollector::run()\n",
            "2   paddle::framework::SignalHandle(char const*, int)\n",
            "3   paddle::platform::GetCurrentTraceBackString[abi:cxx11]()\n",
            "\n",
            "----------------------\n",
            "Error Message Summary:\n",
            "----------------------\n",
            "FatalError: `Termination signal` is detected by the operating system.\n",
            "  [TimeInfo: *** Aborted at 1617312560 (unix time) try \"date -d @1617312560\" if you are using GNU date ***]\n",
            "  [SignalInfo: *** SIGTERM (@0x325) received by PID 808 (TID 0x7f191ce54700) from PID 805 ***]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPoKbR6cCq8_"
      },
      "source": [
        "If you are running this notebook from Google Colab, you can start the dev server with --run-with-ngrok option, to gain acccess to the API endpoint via a public endpoint managed by ngrok:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RodE8ooiCqRw",
        "outputId": "7aec7cf2-71ad-4582-93d0-787a7b8b6a87"
      },
      "source": [
        "!bentoml serve PaddleLinearRegression:latest --run-with-ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n",
            "[2021-04-01 21:30:36,588] INFO - Getting latest version PaddleLinearRegression:20210401212846_F88F15\n",
            "[2021-04-01 21:30:36,609] INFO - Starting BentoML API proxy in development mode..\n",
            "[2021-04-01 21:30:36,611] INFO - Starting BentoML API server in development mode..\n",
            "[2021-04-01 21:30:36,731] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
            "[2021-04-01 21:30:36,750] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.12.0, but loading from BentoML version 0.12.0+14.g0fac537\n",
            "[2021-04-01 21:30:36,751] INFO - Your system nofile limit is 1048576, which means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors for the server process, or launch more microbatch instances to accept more concurrent connection.\n",
            "======== Running on http://0.0.0.0:5000 ========\n",
            "(Press CTRL+C to quit)\n",
            "[2021-04-01 21:30:37,292] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
            "[2021-04-01 21:30:37,309] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.12.0, but loading from BentoML version 0.12.0+14.g0fac537\n",
            "[2021-04-01 21:30:38,624] INFO -  * Running on http://6a59231a38e1.ngrok.io\n",
            "[2021-04-01 21:30:38,624] INFO -  * Traffic stats available on http://127.0.0.1:4040\n",
            "/usr/local/lib/python3.7/dist-packages/paddle/fluid/backward.py:1640: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  return list(x) if isinstance(x, collections.Sequence) else [x]\n",
            " * Serving Flask app \"PaddleLinearRegression\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n",
            "2021-04-01 21:30:39,718 - INFO -  * Running on http://127.0.0.1:36783/ (Press CTRL+C to quit)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMCrkYb5DDHB"
      },
      "source": [
        "# **Make request to the REST server**\n",
        "\n",
        "*After navigating to the location of this notebook, copy and paste the following code to your terminal and run it to make request*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMyLXOIUDXSn"
      },
      "source": [
        "curl -i \\\n",
        "--request POST \\\n",
        "--header \"Content-Type: text/csv\" \\\n",
        "-d @test.csv \\\n",
        "localhost:5000/predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RA0JpPjDMt8"
      },
      "source": [
        "# **Containerize model server with Docker**\n",
        "\n",
        "One common way of distributing this model API server for production deployment, is via Docker containers. And BentoML provides a convenient way to do that.\n",
        "\n",
        "Note that docker is **not available in Google Colab**. You will need to download and run this notebook locally to try out this containerization with docker feature.\n",
        "\n",
        "If you already have docker configured, simply run the follow command to product a docker container serving the PaddleLinearRegression prediction service created above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKUGBMNWDJnr"
      },
      "source": [
        "!bentoml containerize PaddleLinearRegression:latest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nyRChqMDwv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da95549c-1901-484b-8489-d9b0c9706105"
      },
      "source": [
        "!docker run --rm -p 5000:5000 PaddleLinearRegression:20210306050051_766D0A"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: docker: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrnR2hRDD7xf"
      },
      "source": [
        "# **Load Saved Bento Service**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfxsxBRmD1Tx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3dca212-9359-4bd0-b131-ed766576418d"
      },
      "source": [
        "#TODO ADD INPUT\n",
        "from bentoml import load\n",
        "\n",
        "svc = load(saved_path)\n",
        "\n",
        "input = pd.DataFrame([[-0.0405441 ,  0.06636364, -0.32356227, -0.06916996, -0.03435197,\n",
        "        0.05563625, -0.03475696,  0.02682186, -0.37171335, -0.21419304,\n",
        "       -0.33569506,  0.10143217, -0.21172912]]).astype('float32')\n",
        "\n",
        "print(svc.predict(input))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-03-06 05:05:25,666] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.7.8, but loading from BentoML version 0.7.8+402.g8c47823\n",
            "[2021-03-06 05:05:25,669] WARNING - Module `paddle_linear_regression` already loaded, using existing imported module.\n",
            "[2021-03-06 05:05:25,680] WARNING - pip package requirement pandas already exist\n",
            "[2021-03-06 05:05:25,681] WARNING - pip package requirement paddlepaddle already exist\n",
            "[[0.85793805]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlGTKeMnEEyE"
      },
      "source": [
        "# **Launch inference job from CLI**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fgqIWWIEIva",
        "outputId": "5ad69b69-8165-4d7c-d4b8-360838431edf"
      },
      "source": [
        "!bentoml run PaddleLinearRegression:latest predict --format csv --input-file test.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n",
            "[2021-04-01 21:29:58,275] INFO - Getting latest version PaddleLinearRegression:20210401212846_F88F15\n",
            "[2021-04-01 21:29:58,962] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
            "[2021-04-01 21:29:58,978] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.12.0, but loading from BentoML version 0.12.0+14.g0fac537\n",
            "/usr/local/lib/python3.7/dist-packages/paddle/fluid/backward.py:1640: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  return list(x) if isinstance(x, collections.Sequence) else [x]\n",
            "I0401 21:30:01.203775   849 analysis_predictor.cc:155] Profiler is deactivated, and no profiling report will be generated.\n",
            "\u001b[1m\u001b[35m--- Running analysis [ir_graph_build_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [ir_graph_clean_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [ir_analysis_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [simplify_with_basic_ops_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [attention_lstm_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [seqconv_eltadd_relu_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [seqpool_cvm_concat_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [mul_lstm_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [fc_gru_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [mul_gru_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [seq_concat_fc_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [squeeze2_matmul_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [reshape2_matmul_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [flatten2_matmul_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [map_matmul_to_mul_pass]\u001b[0m\n",
            "I0401 21:30:01.213358   849 graph_pattern_detector.cc:101] ---  detected 1 subgraphs\n",
            "\u001b[32m--- Running IR pass [fc_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [repeated_fc_relu_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [squared_mat_sub_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [conv_bn_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [conv_eltwiseadd_bn_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [conv_transpose_bn_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [conv_transpose_eltwiseadd_bn_fuse_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [is_test_pass]\u001b[0m\n",
            "\u001b[32m--- Running IR pass [runtime_context_cache_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [ir_params_sync_among_devices_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [adjust_cudnn_workspace_size_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [inference_op_replace_pass]\u001b[0m\n",
            "\u001b[1m\u001b[35m--- Running analysis [memory_optimize_pass]\u001b[0m\n",
            "I0401 21:30:01.214834   849 memory_optimize_pass.cc:200] Cluster name : linear_1.tmp_2  size: 4\n",
            "I0401 21:30:01.214855   849 memory_optimize_pass.cc:200] Cluster name : linear_1.tmp_1  size: 4\n",
            "I0401 21:30:01.214864   849 memory_optimize_pass.cc:200] Cluster name : x  size: 52\n",
            "I0401 21:30:01.214872   849 memory_optimize_pass.cc:200] Cluster name : x_0  size: 52\n",
            "\u001b[1m\u001b[35m--- Running analysis [ir_graph_to_program_pass]\u001b[0m\n",
            "I0401 21:30:01.216336   849 analysis_predictor.cc:598] ======= optimize end =======\n",
            "I0401 21:30:01.216375   849 naive_executor.cc:107] ---  skip [feed], feed -> x\n",
            "I0401 21:30:01.216478   849 naive_executor.cc:107] ---  skip [linear_1.tmp_1], fetch -> fetch\n",
            "2021-04-01 21:30:01.490969: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "[2021-04-01 21:30:04,291] INFO - {'service_name': 'PaddleLinearRegression', 'service_version': '20210401212846_F88F15', 'api': 'predict', 'task': {'data': '0,1,2,3,4,5,6,7,8,9,10,11,12\\r\\n-0.0405441,0.06636364,-0.32356227,-0.06916996,-0.03435197,0.05563625,-0.03475696,0.02682186,-0.37171335,-0.21419304,-0.33569506,0.10143217,-0.21172912\\r\\n', 'task_id': '951521eb-16e6-4dbf-8ff9-6c596a2c9645', 'batch': 1, 'cli_args': ('--format', 'csv', '--input-file', 'test.csv'), 'inference_job_args': {}}, 'result': {'data': '[[0.9648699760437012]]', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': '951521eb-16e6-4dbf-8ff9-6c596a2c9645'}\n",
            "[[0.9648699760437012]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb-srm9RENeh"
      },
      "source": [
        "# **Deployment Options**\n",
        "\n",
        "If you are at a small team with limited engineering or DevOps resources, try out automated deployment with BentoML CLI, currently supporting AWS Lambda, AWS SageMaker, and Azure Functions:\n",
        "\n",
        "* [AWS Lambda Deployment Guide](https://docs.bentoml.org/en/latest/deployment/aws_lambda.html)\n",
        "* [AWS SageMaker Deployment Guide](https://docs.bentoml.org/en/latest/deployment/aws_sagemaker.html)\n",
        "* [Azure Functions Deployment Guide](https://docs.bentoml.org/en/latest/deployment/azure_functions.html)\n",
        "\n",
        "If the cloud platform you are working with is not on the list above, try out these step-by-step guide on manually deploying BentoML packaged model to cloud platforms:\n",
        "\n",
        "* [AWS ECS Deployment](https://docs.bentoml.org/en/latest/deployment/aws_ecs.html)\n",
        "* [Google Cloud Run Deployment](https://docs.bentoml.org/en/latest/deployment/google_cloud_run.html)\n",
        "* [Azure container instance Deployment](https://docs.bentoml.org/en/latest/deployment/azure_container_instance.html)\n",
        "* [Heroku Deployment](https://docs.bentoml.org/en/latest/deployment/heroku.html)\n",
        "\n",
        "Lastly, if you have a DevOps or ML Engineering team who's operating a Kubernetes or OpenShift cluster, use the following guides as references for implementating your deployment strategy:\n",
        "\n",
        "* [Kubernetes Deployment](https://docs.bentoml.org/en/latest/deployment/kubernetes.html)\n",
        "* [Knative Deployment](https://docs.bentoml.org/en/latest/deployment/knative.html)\n",
        "* [Kubeflow Deployment](https://docs.bentoml.org/en/latest/deployment/kubeflow.html)\n",
        "* [KFServing Deployment](https://docs.bentoml.org/en/latest/deployment/kfserving.html)\n",
        "* [Clipper.ai Deployment Guide](https://docs.bentoml.org/en/latest/deployment/clipper.html)"
      ]
    }
  ]
}