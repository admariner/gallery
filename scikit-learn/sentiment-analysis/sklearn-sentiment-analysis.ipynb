{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BentoML Example: Sentiment Analysis with Scikit-learn\n",
    "\n",
    "BentoML is an open-source framework for machine learning **model serving**, aiming to **bridge the gap between Data Science and DevOps.**\n",
    "\n",
    "Data Scientists can easily package their models trained with any ML framework using BentoMl and reproduce the model for serving in production. BentoML helps with managing packaged models in the BentoML format, and allows DevOps to deploy them as online API serving endpoints or offline batch inference jobs, on any cloud platform.\n",
    "\n",
    "Before reading this example project, be sure to check out the [Getting started guide](https://github.com/bentoml/BentoML/blob/master/guides/quick-start/bentoml-quick-start-guide.ipynb) to learn about the basic concepts in BentoML.\n",
    "\n",
    "This notebook demonstrates how to use BentoML to turn a scikit-learn model into a docker image containing a REST API server serving this model, how to use your ML service built with BentoML as a CLI tool, and how to distribute it a pypi package.\n",
    "\n",
    "\n",
    "*The example is based on [this notebook](https://github.com/crawles/sentiment_analysis_twitter_model/blob/master/build-sentiment-classifier.ipynb), using dataset from [Sentiment140](http://help.sentiment140.com/for-students/)*\n",
    "\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=scikit-learn&ea=scikit-learn-sentiment-analysis&dt=scikit-learn-sentiment-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /usr/local/anaconda3/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/anaconda3/lib/python3.6/site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy in /usr/local/anaconda3/lib/python3.6/site-packages (1.16.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/anaconda3/lib/python3.6/site-packages (from sklearn) (0.19.1)\n",
      "Requirement already satisfied: python-dateutil>=2 in /usr/local/anaconda3/lib/python3.6/site-packages (from pandas) (2.6.1)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/anaconda3/lib/python3.6/site-packages (from pandas) (2017.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/anaconda3/lib/python3.6/site-packages (from python-dateutil>=2->pandas) (1.11.0)\n",
      "\u001b[33mYou are using pip version 18.1, however version 20.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q bentoml 'scikit-learn>=0.23.2' 'pandas>=1.1.1' 'numpy>=1.8.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import bentoml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -f ./trainingandtestdata.zip ]; then\n",
    "    wget -q http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
    "    unzip -n trainingandtestdata.zip\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['polarity', 'tweetid', 'date', 'query_name', 'user', 'text']\n",
    "dftrain = pd.read_csv('training.1600000.processed.noemoticon.csv',\n",
    "                      header = None,\n",
    "                      encoding ='ISO-8859-1')\n",
    "dftest = pd.read_csv('testdata.manual.2009.06.14.csv',\n",
    "                     header = None,\n",
    "                     encoding ='ISO-8859-1')\n",
    "dftrain.columns = columns\n",
    "dftest.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/dev-py3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('count_vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=100,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_lr = Pipeline([\n",
    "                         ('count_vect', CountVectorizer(min_df = 100,\n",
    "                                                        ngram_range = (1,2),\n",
    "                                                        stop_words = 'english')), \n",
    "                         ('lr', LogisticRegression())])\n",
    "sentiment_lr.fit(dftrain.text, dftrain.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84       177\n",
      "           4       0.83      0.88      0.86       182\n",
      "\n",
      "    accuracy                           0.85       359\n",
      "   macro avg       0.85      0.85      0.85       359\n",
      "weighted avg       0.85      0.85      0.85       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Xtest, ytest = dftest.text[dftest.polarity!=2], dftest.polarity[dftest.polarity!=2]\n",
    "print(classification_report(ytest,sentiment_lr.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_lr.predict([Xtest[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BentoService for model serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sentiment_analysis_service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sentiment_analysis_service.py\n",
    "import pandas as pd\n",
    "import bentoml\n",
    "from bentoml.frameworks.sklearn import SklearnModelArtifact\n",
    "from bentoml.service.artifacts.common import PickleArtifact\n",
    "from bentoml.handlers import DataframeHandler\n",
    "from bentoml.adapters import DataframeInput\n",
    "\n",
    "@bentoml.artifacts([PickleArtifact('model')])\n",
    "@bentoml.env(pip_packages=[\"scikit-learn\", \"pandas\"])\n",
    "class SKSentimentAnalysis(bentoml.BentoService):\n",
    "\n",
    "    @bentoml.api(input=DataframeInput(typ='series'))\n",
    "    def predict(self, series):\n",
    "        \"\"\"\n",
    "        predict expects pandas.Series as input\n",
    "        \"\"\"        \n",
    "        return self.artifacts.model.predict(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save BentoService to file archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-01-29 21:09:02,989] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.6.1. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-01-29 21:09:03,037] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.6.1. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-01-29 21:09:03,071] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.6.1. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-01-29 21:09:43,590] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.6.1. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "running sdist\n",
      "running egg_info\n",
      "writing BentoML.egg-info/PKG-INFO\n",
      "writing dependency_links to BentoML.egg-info/dependency_links.txt\n",
      "writing entry points to BentoML.egg-info/entry_points.txt\n",
      "writing requirements to BentoML.egg-info/requires.txt\n",
      "writing top-level names to BentoML.egg-info/top_level.txt\n",
      "reading manifest file 'BentoML.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "no previously-included directories found matching 'examples'\n",
      "no previously-included directories found matching 'tests'\n",
      "no previously-included directories found matching 'docs'\n",
      "warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "warning: no previously-included files matching '*.pyo' found anywhere in distribution\n",
      "warning: no previously-included files matching '.git' found anywhere in distribution\n",
      "warning: no previously-included files matching '.ipynb_checkpoints' found anywhere in distribution\n",
      "warning: no previously-included files matching '__pycache__' found anywhere in distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing manifest file 'BentoML.egg-info/SOURCES.txt'\n",
      "running check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: check: missing meta-data: if 'author' supplied, 'author_email' must be supplied too\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating BentoML-0.6.1+2.gefb0204.dirty\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/BentoML.egg-info\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/artifact\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/bundler\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/cli\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/clipper\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/configuration\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/deployment\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/deployment/aws_lambda\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/deployment/sagemaker\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/handlers\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/migrations\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/migrations/versions\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/proto\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/repository\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/server\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/server/static\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/utils\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/utils/validator\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/yatai\n",
      "creating BentoML-0.6.1+2.gefb0204.dirty/bentoml/yatai/client\n",
      "copying files to BentoML-0.6.1+2.gefb0204.dirty...\n",
      "copying LICENSE -> BentoML-0.6.1+2.gefb0204.dirty\n",
      "copying MANIFEST.in -> BentoML-0.6.1+2.gefb0204.dirty\n",
      "copying README.md -> BentoML-0.6.1+2.gefb0204.dirty\n",
      "copying pyproject.toml -> BentoML-0.6.1+2.gefb0204.dirty\n",
      "copying setup.cfg -> BentoML-0.6.1+2.gefb0204.dirty\n",
      "copying setup.py -> BentoML-0.6.1+2.gefb0204.dirty\n",
      "copying versioneer.py -> BentoML-0.6.1+2.gefb0204.dirty\n",
      "copying BentoML.egg-info/PKG-INFO -> BentoML-0.6.1+2.gefb0204.dirty/BentoML.egg-info\n",
      "copying BentoML.egg-info/SOURCES.txt -> BentoML-0.6.1+2.gefb0204.dirty/BentoML.egg-info\n",
      "copying BentoML.egg-info/dependency_links.txt -> BentoML-0.6.1+2.gefb0204.dirty/BentoML.egg-info\n",
      "copying BentoML.egg-info/entry_points.txt -> BentoML-0.6.1+2.gefb0204.dirty/BentoML.egg-info\n",
      "copying BentoML.egg-info/requires.txt -> BentoML-0.6.1+2.gefb0204.dirty/BentoML.egg-info\n",
      "copying BentoML.egg-info/top_level.txt -> BentoML-0.6.1+2.gefb0204.dirty/BentoML.egg-info\n",
      "copying bentoml/__init__.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml\n",
      "copying bentoml/_version.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml\n",
      "copying bentoml/alembic.ini -> BentoML-0.6.1+2.gefb0204.dirty/bentoml\n",
      "copying bentoml/db.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml\n",
      "copying bentoml/exceptions.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml\n",
      "copying bentoml/service.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml\n",
      "copying bentoml/service_env.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml\n",
      "copying bentoml/artifact/__init__.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/artifact.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/fastai_model_artifact.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/h2o_model_artifact.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/keras_model_artifact.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/lightgbm_model_artifact.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/pickle_artifact.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/pytorch_model_artifact.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/sklearn_model_artifact.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/text_file_artifact.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/tf_savedmodel_artifact.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/artifact\n",
      "copying bentoml/artifact/xgboost_model_artifact.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/artifact\n",
      "copying bentoml/bundler/__init__.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/bundler\n",
      "copying bentoml/bundler/bundler.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/bundler\n",
      "copying bentoml/bundler/config.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/bundler\n",
      "copying bentoml/bundler/loader.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/bundler\n",
      "copying bentoml/bundler/py_module_utils.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/bundler\n",
      "copying bentoml/bundler/templates.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/bundler\n",
      "copying bentoml/bundler/utils.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/bundler\n",
      "copying bentoml/cli/__init__.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/cli\n",
      "copying bentoml/cli/aws_lambda.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/cli\n",
      "copying bentoml/cli/aws_sagemaker.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/cli\n",
      "copying bentoml/cli/bento.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/cli\n",
      "copying bentoml/cli/click_utils.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/cli\n",
      "copying bentoml/cli/config.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/cli\n",
      "copying bentoml/cli/deployment.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/cli\n",
      "copying bentoml/cli/utils.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/cli\n",
      "copying bentoml/clipper/__init__.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/clipper\n",
      "copying bentoml/configuration/__init__.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/configuration\n",
      "copying bentoml/configuration/configparser.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/configuration\n",
      "copying bentoml/configuration/default_bentoml.cfg -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/configuration\n",
      "copying bentoml/deployment/__init__.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/deployment\n",
      "copying bentoml/deployment/operator.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/deployment\n",
      "copying bentoml/deployment/store.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/deployment\n",
      "copying bentoml/deployment/utils.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/deployment\n",
      "copying bentoml/deployment/aws_lambda/__init__.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/deployment/aws_lambda\n",
      "copying bentoml/deployment/aws_lambda/download_extra_resources.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/deployment/aws_lambda\n",
      "copying bentoml/deployment/aws_lambda/lambda_app.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/deployment/aws_lambda\n",
      "copying bentoml/deployment/aws_lambda/utils.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/deployment/aws_lambda\n",
      "copying bentoml/deployment/sagemaker/__init__.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/deployment/sagemaker\n",
      "copying bentoml/deployment/sagemaker/sagemaker_nginx.conf -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/deployment/sagemaker\n",
      "copying bentoml/deployment/sagemaker/sagemaker_serve.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/deployment/sagemaker\n",
      "copying bentoml/deployment/sagemaker/sagemaker_wsgi.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/deployment/sagemaker\n",
      "copying bentoml/handlers/__init__.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/handlers\n",
      "copying bentoml/handlers/base_handlers.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/handlers\n",
      "copying bentoml/handlers/clipper_handler.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/handlers\n",
      "copying bentoml/handlers/dataframe_handler.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/handlers\n",
      "copying bentoml/handlers/fastai_image_handler.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/handlers\n",
      "copying bentoml/handlers/image_handler.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/handlers\n",
      "copying bentoml/handlers/json_handler.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/handlers\n",
      "copying bentoml/handlers/pytorch_tensor_handler.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/handlers\n",
      "copying bentoml/handlers/tensorflow_tensor_handler.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/handlers\n",
      "copying bentoml/handlers/utils.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/handlers\n",
      "copying bentoml/migrations/README -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/migrations\n",
      "copying bentoml/migrations/env.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/migrations\n",
      "copying bentoml/migrations/script.py.mako -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/migrations\n",
      "copying bentoml/migrations/versions/a6b00ae45279_add_last_updated_at_for_deployments.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/migrations/versions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying bentoml/proto/__init__.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/proto\n",
      "copying bentoml/proto/deployment_pb2.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/proto\n",
      "copying bentoml/proto/repository_pb2.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/proto\n",
      "copying bentoml/proto/status_pb2.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/proto\n",
      "copying bentoml/proto/yatai_service_pb2.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/proto\n",
      "copying bentoml/proto/yatai_service_pb2_grpc.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/proto\n",
      "copying bentoml/repository/__init__.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/repository\n",
      "copying bentoml/repository/metadata_store.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/repository\n",
      "copying bentoml/server/__init__.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/server\n",
      "copying bentoml/server/bento_api_server.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/server\n",
      "copying bentoml/server/bento_sagemaker_server.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/server\n",
      "copying bentoml/server/gunicorn_config.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/server\n",
      "copying bentoml/server/gunicorn_server.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/server\n",
      "copying bentoml/server/middlewares.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/server\n",
      "copying bentoml/server/utils.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/server\n",
      "copying bentoml/server/static/swagger-ui-bundle.js -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/server/static\n",
      "copying bentoml/server/static/swagger-ui.css -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/server/static\n",
      "copying bentoml/utils/__init__.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/utils\n",
      "copying bentoml/utils/cloudpickle.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/utils\n",
      "copying bentoml/utils/hybirdmethod.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/utils\n",
      "copying bentoml/utils/log.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/utils\n",
      "copying bentoml/utils/s3.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/utils\n",
      "copying bentoml/utils/tempdir.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/utils\n",
      "copying bentoml/utils/usage_stats.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/utils\n",
      "copying bentoml/utils/validator/__init__.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/utils/validator\n",
      "copying bentoml/yatai/__init__.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/yatai\n",
      "copying bentoml/yatai/deployment_utils.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/yatai\n",
      "copying bentoml/yatai/status.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/yatai\n",
      "copying bentoml/yatai/yatai_service_impl.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/yatai\n",
      "copying bentoml/yatai/client/__init__.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/yatai/client\n",
      "copying bentoml/yatai/client/bento_repository_api.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/yatai/client\n",
      "copying bentoml/yatai/client/deployment_api.py -> BentoML-0.6.1+2.gefb0204.dirty/bentoml/yatai/client\n",
      "Writing BentoML-0.6.1+2.gefb0204.dirty/setup.cfg\n",
      "UPDATING BentoML-0.6.1+2.gefb0204.dirty/bentoml/_version.py\n",
      "set BentoML-0.6.1+2.gefb0204.dirty/bentoml/_version.py to '0.6.1+2.gefb0204.dirty'\n",
      "Creating tar archive\n",
      "removing 'BentoML-0.6.1+2.gefb0204.dirty' (and everything under it)\n",
      "[2020-01-29 21:09:46,434] INFO - BentoService bundle 'SKSentimentAnalysis:20200129210903_E48487' created at: /private/var/folders/kn/xnc9k74x03567n1mx2tfqnpr0000gn/T/bentoml-temp-ibnzwxwb\n",
      "[2020-01-29 21:09:46,435] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.6.1. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-01-29 21:09:46,446] WARNING - Saved BentoService bundle version mismatch: loading BentoServie bundle create with BentoML version 0.6.1,  but loading from BentoML version 0.6.1+0.g4b30c1a.dirty\n",
      "[2020-01-29 21:09:46,832] INFO - BentoService bundle 'SKSentimentAnalysis:20200129210903_E48487' created at: /Users/bozhaoyu/bentoml/repository/SKSentimentAnalysis/20200129210903_E48487\n"
     ]
    }
   ],
   "source": [
    "# 1) import the custom BentoService defined above\n",
    "from sentiment_analysis_service import SKSentimentAnalysis\n",
    "\n",
    "# 2) `pack` it with required artifacts\n",
    "bento_service = SKSentimentAnalysis()\n",
    "bento_service.pack('model', sentiment_lr)\n",
    "\n",
    "# 3) save your BentoSerivce to file archive\n",
    "saved_path = bento_service.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REST API Model Serving\n",
    "\n",
    "\n",
    "To start a REST API model server with the BentoService saved above, use the bentoml serve command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-01-28 10:11:44,198] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.6.1. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-01-28 10:11:44,209] WARNING - Saved BentoService bundle version mismatch: loading BentoServie bundle create with BentoML version 0.6.1,  but loading from BentoML version 0.6.1+1.g2647cf3.dirty\n",
      "[2020-01-28 10:11:44,551] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.6.1. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-01-28 10:12:04,950] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.6.1. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      " * Serving Flask app \"SKSentimentAnalysis\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n",
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve SKSentimentAnalysis:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running this notebook from Google Colab, you can start the dev server with `--run-with-ngrok` option, to gain acccess to the API endpoint via a public endpoint managed by [ngrok](https://ngrok.com/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve SKSentimentAnalysis:latest --run-with-ngrok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send prediction request to REST API server\n",
    "\n",
    "Run the following command in terminal to make a HTTP request to the API server:\n",
    "```bash\n",
    "curl -i \\\n",
    "--header \"Content-Type: application/json\" \\\n",
    "--request POST \\\n",
    "--data '[\"some new text, sweet noodles\", \"happy time\", \"sad day\"]' \\\n",
    "localhost:5000/predict\n",
    "```\n",
    "\n",
    "You can also view all availabl API endpoints at [localhost:5000](localhost:5000), or look at prometheus metrics at [localhost:5000/metrics](localhost:5000/metrics) in browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Containerize model server with Docker\n",
    "\n",
    "\n",
    "One common way of distributing this model API server for production deployment, is via Docker containers. And BentoML provides a convenient way to do that.\n",
    "\n",
    "Note that docker is **not available in Google Colab**. You will need to download and run this notebook locally to try out this containerization with docker feature.\n",
    "\n",
    "If you already have docker configured, simply run the follow command to product a docker container serving the IrisClassifier prediction service created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  123.4MB\n",
      "Step 1/12 : FROM continuumio/miniconda3:4.7.12\n",
      " ---> 406f2b43ea59\n",
      "Step 2/12 : ENTRYPOINT [ \"/bin/bash\", \"-c\" ]\n",
      " ---> Using cache\n",
      " ---> 28172be83c07\n",
      "Step 3/12 : EXPOSE 5000\n",
      " ---> Using cache\n",
      " ---> 840844d191d4\n",
      "Step 4/12 : RUN set -x      && apt-get update      && apt-get install --no-install-recommends --no-install-suggests -y libpq-dev build-essential      && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 243c05e712f3\n",
      "Step 5/12 : RUN conda install pip numpy scipy       && pip install gunicorn\n",
      " ---> Using cache\n",
      " ---> 8fab95ab34fc\n",
      "Step 6/12 : COPY . /bento\n",
      " ---> 67d9e50d566b\n",
      "Step 7/12 : WORKDIR /bento\n",
      " ---> Running in b3dcad063ce1\n",
      "Removing intermediate container b3dcad063ce1\n",
      " ---> f14962580e56\n",
      "Step 8/12 : RUN if [ -f /bento/setup.sh ]; then /bin/bash -c /bento/setup.sh; fi\n",
      " ---> Running in 93e35cb1765b\n",
      "Removing intermediate container 93e35cb1765b\n",
      " ---> b274d4877198\n",
      "Step 9/12 : RUN conda env update -n base -f /bento/environment.yml\n",
      " ---> Running in 2ecba597d9d5\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pip-20.0.2           | 1.7 MB    | ########## | 100% \n",
      "python-3.7.3         | 32.1 MB   | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate base\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "Removing intermediate container 2ecba597d9d5\n",
      " ---> cfebc200ccb1\n",
      "Step 10/12 : RUN pip install -r /bento/requirements.txt\n",
      " ---> Running in 9518c92df6f6\n",
      "\u001b[91mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[0mCollecting bentoml==0.6.1\n",
      "  Downloading BentoML-0.6.1-py3-none-any.whl (553 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.22.1-cp37-cp37m-manylinux1_x86_64.whl (7.0 MB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from bentoml==0.6.1->-r /bento/requirements.txt (line 1)) (1.18.1)\n",
      "Collecting ruamel.yaml>=0.15.0\n",
      "  Downloading ruamel.yaml-0.16.6-py2.py3-none-any.whl (123 kB)\n",
      "Collecting protobuf>=3.6.0\n",
      "  Downloading protobuf-3.11.2-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: gunicorn in /opt/conda/lib/python3.7/site-packages (from bentoml==0.6.1->-r /bento/requirements.txt (line 1)) (20.0.4)\n",
      "Collecting alembic\n",
      "  Downloading alembic-1.3.3.tar.gz (1.1 MB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from bentoml==0.6.1->-r /bento/requirements.txt (line 1)) (2.22.0)\n",
      "Collecting docker\n",
      "  Downloading docker-4.1.0-py2.py3-none-any.whl (139 kB)\n",
      "Collecting python-json-logger\n",
      "  Downloading python-json-logger-0.1.11.tar.gz (6.0 kB)\n",
      "Collecting prometheus-client\n",
      "  Downloading prometheus_client-0.7.1.tar.gz (38 kB)\n",
      "Collecting flask\n",
      "  Downloading Flask-1.1.1-py2.py3-none-any.whl (94 kB)\n",
      "Collecting humanfriendly\n",
      "  Downloading humanfriendly-4.18-py2.py3-none-any.whl (73 kB)\n",
      "Collecting python-dateutil<2.8.1,>=2.1\n",
      "  Downloading python_dateutil-2.8.0-py2.py3-none-any.whl (226 kB)\n",
      "Collecting packaging\n",
      "  Downloading packaging-20.1-py2.py3-none-any.whl (36 kB)\n",
      "Collecting cerberus\n",
      "  Downloading Cerberus-1.3.2.tar.gz (52 kB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.11.9-py2.py3-none-any.whl (128 kB)\n",
      "Collecting configparser\n",
      "  Downloading configparser-4.0.2-py2.py3-none-any.whl (22 kB)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.6.tar.gz (45 kB)\n",
      "Collecting grpcio\n",
      "  Downloading grpcio-1.26.0-cp37-cp37m-manylinux2010_x86_64.whl (2.4 MB)\n",
      "Collecting click>=7.0\n",
      "  Downloading Click-7.0-py2.py3-none-any.whl (81 kB)\n",
      "Collecting sqlalchemy>=1.3.0\n",
      "  Downloading SQLAlchemy-1.3.13.tar.gz (6.0 MB)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->-r /bento/requirements.txt (line 2)) (1.3.2)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2019.3-py2.py3-none-any.whl (509 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.8\"\n",
      "  Downloading ruamel.yaml.clib-0.2.0-cp37-cp37m-manylinux1_x86_64.whl (547 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.0->bentoml==0.6.1->-r /bento/requirements.txt (line 1)) (41.4.0)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.0->bentoml==0.6.1->-r /bento/requirements.txt (line 1)) (1.12.0)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.1.tar.gz (468 kB)\n",
      "Collecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->bentoml==0.6.1->-r /bento/requirements.txt (line 1)) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->bentoml==0.6.1->-r /bento/requirements.txt (line 1)) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->bentoml==0.6.1->-r /bento/requirements.txt (line 1)) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->bentoml==0.6.1->-r /bento/requirements.txt (line 1)) (3.0.4)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Collecting Jinja2>=2.10.1\n",
      "  Downloading Jinja2-2.11.0-py2.py3-none-any.whl (126 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Werkzeug>=0.15\n",
      "  Downloading Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Downloading pyparsing-2.4.6-py2.py3-none-any.whl (67 kB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.9.4-py2.py3-none-any.whl (24 kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.2-py2.py3-none-any.whl (69 kB)\n",
      "Collecting botocore<1.15.0,>=1.14.9\n",
      "  Downloading botocore-1.14.9-py2.py3-none-any.whl (5.9 MB)\n",
      "Collecting MarkupSafe>=0.9.2\n",
      "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (27 kB)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Building wheels for collected packages: alembic, python-json-logger, prometheus-client, cerberus, tabulate, sqlalchemy, Mako\n",
      "  Building wheel for alembic (setup.py): started\n",
      "  Building wheel for alembic (setup.py): finished with status 'done'\n",
      "  Created wheel for alembic: filename=alembic-1.3.3-py2.py3-none-any.whl size=155684 sha256=3167806ac6b0296dc1735b8db3d939d5e979caf1217b723341dd8c88aa6259f1\n",
      "  Stored in directory: /root/.cache/pip/wheels/71/63/41/f20802c61cc6cf93b6d71ff017970ae2d3a79f7d143627a0f1\n",
      "  Building wheel for python-json-logger (setup.py): started\n",
      "  Building wheel for python-json-logger (setup.py): finished with status 'done'\n",
      "  Created wheel for python-json-logger: filename=python_json_logger-0.1.11-py2.py3-none-any.whl size=5076 sha256=9e68a1af7f989755feec41015eed7365d23fcb792e02f4b8f075ec7e4799ed1f\n",
      "  Stored in directory: /root/.cache/pip/wheels/fa/7f/fd/92ccdbb9d1a65486406e0363d2ba5b4ce52f400a915f602ecb\n",
      "  Building wheel for prometheus-client (setup.py): started\n",
      "  Building wheel for prometheus-client (setup.py): finished with status 'done'\n",
      "  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-py3-none-any.whl size=41402 sha256=5d83f05f97a3c7353efcaf51968d6c09d25d71342583c992356d1569d6494ea3\n",
      "  Stored in directory: /root/.cache/pip/wheels/30/0c/26/59ba285bf65dc79d195e9b25e2ddde4c61070422729b0cd914\n",
      "  Building wheel for cerberus (setup.py): started\n",
      "  Building wheel for cerberus (setup.py): finished with status 'done'\n",
      "  Created wheel for cerberus: filename=Cerberus-1.3.2-py3-none-any.whl size=54335 sha256=c089498419684e5e81d4550bbb303abfae56940a60c1dc7cd4aa2b1797980e07\n",
      "  Stored in directory: /root/.cache/pip/wheels/17/3a/0d/e2fc48cf85cb858f5e65f1baa36180ebb5dce6397c35c4cfcb\n",
      "  Building wheel for tabulate (setup.py): started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for tabulate (setup.py): finished with status 'done'\n",
      "  Created wheel for tabulate: filename=tabulate-0.8.6-py3-none-any.whl size=23273 sha256=1e2ac06f60ddd211e05f0f23937233a0f1e6d42ff7d553069f710098fd730b50\n",
      "  Stored in directory: /root/.cache/pip/wheels/09/b6/7e/08b4ee715a1239453e89a59081f0ac369a9036f232e013ecd8\n",
      "  Building wheel for sqlalchemy (setup.py): started\n",
      "  Building wheel for sqlalchemy (setup.py): finished with status 'done'\n",
      "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.3.13-cp37-cp37m-linux_x86_64.whl size=1223709 sha256=a3589c89331982830cf1bba0187eec69217d2be87bebdda137be736aca59b877\n",
      "  Stored in directory: /root/.cache/pip/wheels/b9/ba/77/163f10f14bd489351530603e750c195b0ceceed2f3be2b32f1\n",
      "  Building wheel for Mako (setup.py): started\n",
      "  Building wheel for Mako (setup.py): finished with status 'done'\n",
      "  Created wheel for Mako: filename=Mako-1.1.1-py3-none-any.whl size=75409 sha256=ac1c12f7fb3cd5c184dd788db6805a3a09b890477305c63b50a5bc0ac162fe36\n",
      "  Stored in directory: /root/.cache/pip/wheels/11/fe/fa/3693b62cf5ec2b2784b6496734f0ee3e2321eb66d66607e5f9\n",
      "Successfully built alembic python-json-logger prometheus-client cerberus tabulate sqlalchemy Mako\n",
      "Installing collected packages: ruamel.yaml.clib, ruamel.yaml, protobuf, sqlalchemy, MarkupSafe, Mako, python-editor, python-dateutil, alembic, websocket-client, docker, python-json-logger, prometheus-client, Jinja2, itsdangerous, Werkzeug, click, flask, humanfriendly, pyparsing, packaging, cerberus, jmespath, docutils, botocore, s3transfer, boto3, configparser, tabulate, pytz, pandas, grpcio, bentoml, joblib, scikit-learn\n",
      "Successfully installed Jinja2-2.11.0 Mako-1.1.1 MarkupSafe-1.1.1 Werkzeug-0.16.1 alembic-1.3.3 bentoml-0.6.1 boto3-1.11.9 botocore-1.14.9 cerberus-1.3.2 click-7.0 configparser-4.0.2 docker-4.1.0 docutils-0.15.2 flask-1.1.1 grpcio-1.26.0 humanfriendly-4.18 itsdangerous-1.1.0 jmespath-0.9.4 joblib-0.14.1 packaging-20.1 pandas-0.25.3 prometheus-client-0.7.1 protobuf-3.11.2 pyparsing-2.4.6 python-dateutil-2.8.0 python-editor-1.0.4 python-json-logger-0.1.11 pytz-2019.3 ruamel.yaml-0.16.6 ruamel.yaml.clib-0.2.0 s3transfer-0.3.2 scikit-learn-0.22.1 sqlalchemy-1.3.13 tabulate-0.8.6 websocket-client-0.57.0\n",
      "Removing intermediate container 9518c92df6f6\n",
      " ---> 30f398610491\n",
      "Step 11/12 : RUN if [ -f /bento/bentoml_init.sh ]; then /bin/bash -c /bento/bentoml_init.sh; fi\n",
      " ---> Running in 26fac21e185c\n",
      "\u001b[91mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[0mProcessing ./bundled_pip_dependencies/BentoML-0.6.1.tar.gz\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<2.8.1,>=2.1 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: humanfriendly in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (4.18)\n",
      "Requirement already satisfied, skipping upgrade: docker in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: gunicorn in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (20.0.4)\n",
      "Requirement already satisfied, skipping upgrade: configparser in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (4.0.2)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (0.25.3)\n",
      "Requirement already satisfied, skipping upgrade: tabulate in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (0.8.6)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (3.11.2)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: flask in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: ruamel.yaml>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (0.16.6)\n",
      "Requirement already satisfied, skipping upgrade: python-json-logger in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (0.1.11)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-client in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: grpcio in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (1.26.0)\n",
      "Requirement already satisfied, skipping upgrade: cerberus in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (1.3.2)\n",
      "Requirement already satisfied, skipping upgrade: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (1.3.13)\n",
      "Requirement already satisfied, skipping upgrade: alembic in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (1.3.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (20.1)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.6.1) (1.11.9)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<2.8.1,>=2.1->BentoML==0.6.1) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from docker->BentoML==0.6.1) (0.57.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=3.0 in /opt/conda/lib/python3.7/site-packages (from gunicorn->BentoML==0.6.1) (41.4.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->BentoML==0.6.1) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->BentoML==0.6.1) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->BentoML==0.6.1) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->BentoML==0.6.1) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->BentoML==0.6.1) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/lib/python3.7/site-packages (from flask->BentoML==0.6.1) (0.16.1)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /opt/conda/lib/python3.7/site-packages (from flask->BentoML==0.6.1) (2.11.0)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/lib/python3.7/site-packages (from flask->BentoML==0.6.1) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from ruamel.yaml>=0.15.0->BentoML==0.6.1) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: python-editor>=0.3 in /opt/conda/lib/python3.7/site-packages (from alembic->BentoML==0.6.1) (1.0.4)\n",
      "Requirement already satisfied, skipping upgrade: Mako in /opt/conda/lib/python3.7/site-packages (from alembic->BentoML==0.6.1) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->BentoML==0.6.1) (2.4.6)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->BentoML==0.6.1) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3->BentoML==0.6.1) (0.3.2)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.15.0,>=1.14.9 in /opt/conda/lib/python3.7/site-packages (from boto3->BentoML==0.6.1) (1.14.9)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask->BentoML==0.6.1) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from botocore<1.15.0,>=1.14.9->boto3->BentoML==0.6.1) (0.15.2)\n",
      "Building wheels for collected packages: BentoML\n",
      "  Building wheel for BentoML (PEP 517): started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for BentoML (PEP 517): finished with status 'done'\n",
      "  Created wheel for BentoML: filename=BentoML-0.6.1-py3-none-any.whl size=505667 sha256=c1f6b20b28250256f356e879575619a1171470fb1727f3b3635238ed322cd6fd\n",
      "  Stored in directory: /root/.cache/pip/wheels/a2/b5/f6/4b37cd2a90c23d57718be64cb02a49396cc1f8014ebe1612b2\n",
      "Successfully built BentoML\n",
      "Installing collected packages: BentoML\n",
      "  Attempting uninstall: BentoML\n",
      "    Found existing installation: BentoML 0.6.1\n",
      "    Uninstalling BentoML-0.6.1:\n",
      "      Successfully uninstalled BentoML-0.6.1\n",
      "Successfully installed BentoML-0.6.1\n",
      "Removing intermediate container 26fac21e185c\n",
      " ---> 08ce88940dae\n",
      "Step 12/12 : CMD [\"bentoml serve-gunicorn /bento\"]\n",
      " ---> Running in 509e19e67e04\n",
      "Removing intermediate container 509e19e67e04\n",
      " ---> 1597af914b10\n",
      "Successfully built 1597af914b10\n",
      "Successfully tagged sk-sentiment-analysis:latest\n"
     ]
    }
   ],
   "source": [
    "!bentoml containerize SKSentimentAnalysis:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-01-28 00:12:41,498] INFO - get_gunicorn_num_of_workers: 3, calculated by cpu count\n",
      "[2020-01-28 00:12:41 +0000] [1] [INFO] Starting gunicorn 20.0.4\n",
      "[2020-01-28 00:12:41 +0000] [1] [INFO] Listening at: http://0.0.0.0:5000 (1)\n",
      "[2020-01-28 00:12:41 +0000] [1] [INFO] Using worker: sync\n",
      "[2020-01-28 00:12:41 +0000] [9] [INFO] Booting worker with pid: 9\n",
      "[2020-01-28 00:12:41 +0000] [10] [INFO] Booting worker with pid: 10\n",
      "[2020-01-28 00:12:41 +0000] [11] [INFO] Booting worker with pid: 11\n",
      "^C\n",
      "[2020-01-28 00:12:53 +0000] [1] [INFO] Handling signal: int\n"
     ]
    }
   ],
   "source": [
    "!docker run -p 5000:5000 sk-sentiment-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved BentoService\n",
    "\n",
    "bentoml.load is the API for loading a BentoML packaged model in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-01-29 20:59:11,946] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.6.1. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-01-29 20:59:11,956] WARNING - Saved BentoService bundle version mismatch: loading BentoServie bundle create with BentoML version 0.6.1,  but loading from BentoML version 0.6.1+0.g4b30c1a.dirty\n",
      "[2020-01-29 20:59:11,957] WARNING - Module `sentiment_analysis_service` already loaded, using existing imported module.\n",
      "[2020-01-29 20:59:29,061] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.6.1. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 4])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bentoml\n",
    "\n",
    "# Load exported bentoML model archive from path\n",
    "loaded_bento_service = bentoml.load(saved_path)\n",
    "\n",
    "# Call predict on the restored sklearn model\n",
    "loaded_bento_service.predict(pd.Series([\"good\", \"great\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch inference job from CLI\n",
    "\n",
    "BentoML cli supports loading and running a packaged model from CLI. With the DataframeInput adapter, the CLI command supports reading input Dataframe data from CLI argument or local csv or json files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-01-29 21:26:23,608] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.6.1. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-01-29 21:26:23,626] WARNING - Saved BentoService bundle version mismatch: loading BentoServie bundle create with BentoML version 0.6.1,  but loading from BentoML version 0.6.1+2.gefb0204.dirty\n",
      "[2020-01-29 21:26:24,203] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.6.1. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-01-29 21:26:41,449] WARNING - BentoML local changes detected - Local BentoML repository including all code changes will be bundled together with the BentoService bundle. When used with docker, the base docker image will be default to same version as last PyPI release at version: 0.6.1. You can also force bentoml to use a specific version for deploying your BentoService bundle, by setting the config 'core/bentoml_deploy_version' to a pinned version or your custom BentoML on github, e.g.:'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[4 4 0]\n"
     ]
    }
   ],
   "source": [
    "!bentoml run SKSentimentAnalysis:20200129205654_0D29B1 predict \\\n",
    "--input '[\"some new text, sweet noodles\", \"happy time\", \"sad day\"]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment Options\n",
    "\n",
    "If you are at a small team with limited engineering or DevOps resources, try out automated deployment with BentoML CLI, currently supporting AWS Lambda, AWS SageMaker, and Azure Functions:\n",
    "- [AWS Lambda Deployment Guide](https://docs.bentoml.org/en/latest/deployment/aws_lambda.html)\n",
    "- [AWS SageMaker Deployment Guide](https://docs.bentoml.org/en/latest/deployment/aws_sagemaker.html)\n",
    "- [Azure Functions Deployment Guide](https://docs.bentoml.org/en/latest/deployment/azure_functions.html)\n",
    "\n",
    "If the cloud platform you are working with is not on the list above, try out these step-by-step guide on manually deploying BentoML packaged model to cloud platforms:\n",
    "- [AWS ECS Deployment](https://docs.bentoml.org/en/latest/deployment/aws_ecs.html)\n",
    "- [Google Cloud Run Deployment](https://docs.bentoml.org/en/latest/deployment/google_cloud_run.html)\n",
    "- [Azure container instance Deployment](https://docs.bentoml.org/en/latest/deployment/azure_container_instance.html)\n",
    "- [Heroku Deployment](https://docs.bentoml.org/en/latest/deployment/heroku.html)\n",
    "\n",
    "Lastly, if you have a DevOps or ML Engineering team who's operating a Kubernetes or OpenShift cluster, use the following guides as references for implementating your deployment strategy:\n",
    "- [Kubernetes Deployment](https://docs.bentoml.org/en/latest/deployment/kubernetes.html)\n",
    "- [Knative Deployment](https://docs.bentoml.org/en/latest/deployment/knative.html)\n",
    "- [Kubeflow Deployment](https://docs.bentoml.org/en/latest/deployment/kubeflow.html)\n",
    "- [KFServing Deployment](https://docs.bentoml.org/en/latest/deployment/kfserving.html)\n",
    "- [Clipper.ai Deployment Guide](https://docs.bentoml.org/en/latest/deployment/clipper.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
